# Configs
data_file = /proj/BigLearning/hengganc/data/mlr_data/imagenet_llc/imnet.train.50.train
ROW_DATA_SIZE = 21504
val_t = float

# Nome: Using synced mem and petuum's algebra functions
count = -3.58519
predict_time = 3.68405
outer_product_time = 6.87247
make_y_time = 0.00020968
dotproduct_time = 3.67802
softmax_time = 0.0057963

# Nome: Using caffe_cpu math functions
predict_time = 3.37941
outer_product_time = 7.68918
make_y_time = 0.000156411
dotproduct_time = 3.37347
softmax_time = 0.00540422

# Nome: Represent w_cache and w_delta as single SyncedMemories
predict_time = 3.26017
outer_product_time = 5.73572
make_y_time = 0
dotproduct_time = 3.13884
softmax_time = 0.00575641

# Nome: Replace dot product with matrix multiplication
count = -3.58526
predict_time = 1.77308
outer_product_time = 5.87122
make_y_time = 0
dotproduct_time = 1.65388
softmax_time = 0.00566509

# Nome: Use matrix multiplication for outer product
count = -3.58524
predict_time = 1.72748
outer_product_time = 5.71182
make_y_time = 0
dotproduct_time = 1.60817
softmax_time = 0.00532832

# Susitna: caffe CPU math functions
count = -3.58524
predict_time = 0.864054
outer_product_time = 4.85773
make_y_time = 0
dotproduct_time = 0.812473
softmax_time = 0.00417769

# Susitna: caffe CPU, no softmax or y_vec adjustment
count = 0
alloc_mem_time = 0.0470124
predict_time = 0.818194
outer_product_time = 4.88337
dotproduct_time = 0.818146
softmax_time = 3.2013e-05

# Susitna: caffe GPU, no softmax or y_vec adjustment
count = 0
alloc_mem_time = 1.7627
predict_time = 0.15931
outer_product_time = 0.000647245
dotproduct_time = 0.159291
softmax_time = 6.625e-06
35.6x faster without alloc_mem_time
3x faster with alloc_mem_time

# Susitna: caffe CPU, do softmax and y_vec adjustment
count = -3.58524
alloc_mem_time = 2.1463e-05
dotproduct_time = 0.819699
softmax_time = 0.00416522
outer_product_time = 4.85702

# Susitna: caffe GPU, do softmax and y_vec adjustment by moving data back to CPU
count = -3.58524
alloc_mem_time = 8.447e-06
dotproduct_time = 0.1564
softmax_time = 0.177294
outer_product_time = 0.000595494
17x speed up

# Susitna: caffe CPU, do softmax and y_vec adjustment
num_possitives = 278487
sum = -3.58524
refresh_weights_time = 1.82e-07
alloc_mem_time = 1.8573e-05
dotproduct_time = 0.819757
softmax_time = 0.00430152
outer_product_time = 4.85962
change_weights_time = 2.96e-07
total_compute_time = 5.6837
total_time = 5.6837

# Susitna: caffe GPU, do softmax and y_vec adjustment using kernel function
num_possitives = 278494
sum = 0.134465
refresh_weights_time = 0.175778
alloc_mem_time = 7.89e-06
dotproduct_time = 0.000382452
softmax_time = 0.000391891
outer_product_time = 0.000580664
change_weights_time = 0.371294
total_compute_time = 0.0013629
(4000x speed up)
total_time = 0.548435
(10x speed up)

# Susitna, GPU, device synchronize after kernel calls
hengganc@h0:~/cuitest/mlr_test$ ./mlr 0 50
num_possitives = 278494
sum = 0.134465
refresh_weights_time = 0.111842
alloc_mem_time = 0.000440285
dotproduct_time = 0.0433198
softmax_time = 0.10884
outer_product_time = 0.133496
change_weights_time = 0.0560405
total_compute_time = 0.286096
total_time = 0.453979

# 05/21/2015: GPU vs CPU
batch size	gpu	cpu	speedup
50	0.453979	7.74242	17.05457741
100	0.761295	12.9589	17.02217931
200	1.31326	24.8508	18.92298555
400	2.45873	47.0712	19.1445177
800	4.83742	92.9185	19.20827631

# 05/21/2015: batched SGD: GPU vs CPU
gpu-batched	cpu-batched	speedup
0.34	0.476631	1.401855882
0.34	0.723378	2.127582353
0.34	1.38656	4.078117647
0.34	2.74567	8.0755
0.34	5.60438	16.48347059
